import zipfile
import os
from PIL import Image
from os import listdir
from os.path import isdir, join
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelBinarizer
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import VGG19
from tensorflow.keras.utils import to_categorical
from tensorflow.keras import layers
from tensorflow.keras import models
from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
from mlxtend.plotting import plot_confusion_matrix

caminho_zip = '/diretorio'
caminho_extracao = '/diretorio_extracao'
with zipfile.ZipFile(caminho_zip, 'r') as zip_ref:
    zip_ref.extractall(caminho_extracao)

def select_image(filename):
    image = Image.open(filename)
    image = image.convert('RGB')

    width, height = image.size

    new_height = int(height * 0.8)

    image = image.crop((0, 0, width, new_height))

    image = image.resize((300, 300))

    return np.asarray(image)

def load_class(diretorio, classe, imagens, labels, filepaths):
    for filename in listdir(diretorio):
        path = join(diretorio, filename)
        try:
            imagens.append(select_image(path))
            labels.append(classe)
            filepaths.append(path)
        except:
            print("Erro ao ler imagem {}".format(path))
    return imagens, labels, filepaths

def select_data_set(diretorio_caso, diretorio_controle):
    imagens, labels, filepaths = list(), list(), list()
    imagens, labels, filepaths = load_class(diretorio_caso, 'caso', imagens, labels, filepaths)
    imagens, labels, filepaths = load_class(diretorio_controle, 'controle', imagens, labels, filepaths)
    return imagens, labels, filepaths

# Parâmetros e variáveis
batch_size = 32
input_shape = (300, 300, 3)
random_state = 42
alpha = 1e-5
epoch = 25
num_runs = 10  
accs, sens, specs = [], [], []  

dataset_caso = '/diretorio_caso'
dataset_controle = '/content/dataset/PEP-controle/diretorio_controle'

imagens, labels, filepaths = select_data_set(dataset_caso, dataset_controle)

imagens = np.array(imagens) / 255.0
labels = np.array(labels)

lb = LabelBinarizer()
labels = lb.fit_transform(labels)
labels = to_categorical(labels)

def augment_control_images(images, labels, filepaths, augment_factor=3):
    control_images = [img for img, label in zip(images, labels) if np.argmax(label) == 1]
    control_labels = [label for label in labels if np.argmax(label) == 1]
    control_filepaths = [path for path, label in zip(filepaths, labels) if np.argmax(label) == 1]

    print(f"Antes da ampliação: {len(control_images)} imagens do grupo controle")

    augmented_images = []
    augmented_labels = []
    augmented_filepaths = []

    datagen = ImageDataGenerator(
        rotation_range=20,
        zoom_range=0.2,
    )

    for img, label, path in zip(control_images, control_labels, control_filepaths):
        img = np.expand_dims(img, 0)
        it = datagen.flow(img, batch_size=1)
        for _ in range(augment_factor - 1):
            augmented_image = next(it)[0].astype(np.uint8)
            augmented_images.append(augmented_image)
            augmented_labels.append(label)
            augmented_filepaths.append(path)

    images = np.concatenate([images, np.array(augmented_images)], axis=0)
    labels = np.concatenate([labels, np.array(augmented_labels)], axis=0)
    filepaths.extend(augmented_filepaths)  # Não precisa converter para np.array

    print(f"Após a ampliação: {len(images)} imagens totais")

    return images, labels, filepaths

imagens, labels, filepaths = augment_control_images(imagens, labels, filepaths)

def augment_all_images(images, labels, filepaths, augment_factor=20):
    print(f"Antes da ampliação: {len(images)} imagens totais")

    datagen = ImageDataGenerator(
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.2,
    )

    augmented_images = []
    augmented_labels = []
    augmented_filepaths = []

    for img, label, path in zip(images, labels, filepaths):
        img = np.expand_dims(img, 0)
        it = datagen.flow(img, batch_size=1)
        for _ in range(augment_factor - 1):  # Não precisa gerar a imagem original
            augmented_image = next(it)[0].astype(np.uint8)
            augmented_images.append(augmented_image)
            augmented_labels.append(label)
            augmented_filepaths.append(path)  # Manter o caminho original

    images = np.concatenate([images, np.array(augmented_images)], axis=0)
    labels = np.concatenate([labels, np.array(augmented_labels)], axis=0)
    filepaths.extend(augmented_filepaths)  # Não precisa converter para np.array

    print(f"Após a ampliação: {len(images)} imagens totais")

    return images, labels, filepaths

augment_factor = 20  # Fator de aumento, ajuste conforme necessário
imagens, labels, filepaths = augment_all_images(imagens, labels, filepaths)

for run in range(num_runs):
    print(f"Execução {run + 1}/{num_runs}")

    filepath = f"Modelo_salvo_{run + 1}.keras"
    checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')
    lr_reduce = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, min_delta=alpha, patience=5, verbose=1)
    callbacks = [checkpoint, lr_reduce]

    (trainX, testX, trainY, testY, train_paths, test_paths) = train_test_split(
        imagens, labels, filepaths, test_size=0.25, stratify=labels, random_state=run
    )

    conv_base = VGG19(weights='imagenet', include_top=False, input_shape=input_shape)
    conv_base.trainable = True
    set_trainable = False

    for layer in conv_base.layers:
        if layer.name == 'block5_conv1':
            set_trainable = True
        if set_trainable:
            layer.trainable = True
        else:
            layer.trainable = False

    model = models.Sequential()
    model.add(conv_base)
    model.add(layers.GlobalAveragePooling2D())
    model.add(layers.BatchNormalization())
    model.add(layers.Flatten())
    model.add(layers.Dense(64, activation='relu'))
    model.add(layers.Dropout(0.9))
    model.add(layers.Dense(2, activation='softmax'))

    model.compile(loss='binary_crossentropy',
                  optimizer='adam',
                  metrics=['accuracy'])

    history = model.fit(trainX, trainY,
                        validation_data=(testX, testY),
                        callbacks=callbacks,
                        epochs=epoch,
                        batch_size=batch_size)

    plt.figure(figsize=(12, 5))

    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], label='Treinamento')
    plt.plot(history.history['val_accuracy'], label='Validação')
    plt.title('Acurácia')
    plt.xlabel('Épocas')
    plt.ylabel('Acurácia')
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], label='Treinamento')
    plt.plot(history.history['val_loss'], label='Validação')
    plt.title('Perda')
    plt.xlabel('Épocas')
    plt.ylabel('Perda')
    plt.legend()

    plt.show()

    pred = model.predict(testX, batch_size=batch_size)
    pred = np.argmax(pred, axis=1)
    testY_max = np.argmax(testY, axis=1)
    cm = confusion_matrix(testY_max, pred)
    plot_confusion_matrix(cm, class_names=lb.classes_)

    tn, fp, fn, tp = cm.ravel()
    accuracy = (tp + tn) / (tp + tn + fp + fn)
    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)

    accs.append(accuracy)
    sens.append(sensitivity)
    specs.append(specificity)

accs_mean, sens_mean, specs_mean = np.mean(accs), np.mean(sens), np.mean(specs)
accs_std, sens_std, specs_std = np.std(accs), np.std(sens), np.std(specs)

print(f"Acurácia média: {accs_mean:.4f} ± {accs_std:.4f}")
print(f"Sensibilidade média: {sens_mean:.4f} ± {sens_std:.4f}")
print(f"Especificidade média: {specs_mean:.4f} ± {specs_std:.4f}")
